{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cb0dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1,2,3], [4,5,6],[7,8,9]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98edcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef488ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 2\n",
    "x_train, y_train = make_blobs(n_samples=80, n_features=n_dim, \\\n",
    "centers=[[1,1],[-1,-1],[1,-1],[-1,1]], shuffle=True, cluster_std=0.3)\n",
    "x_test, y_test = make_blobs(n_samples=20, n_features=n_dim, \\\n",
    "centers=[[1,1],[-1,-1],[1,-1],[-1,1]], shuffle=True, cluster_std=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f32f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(y_, from_, to_):\n",
    "    y = numpy.copy(y_)\n",
    "    for f in from_:\n",
    "        y[y_ == f] = to_\n",
    "    return y\n",
    "\n",
    "y_train = label_map(y_train, [0, 1], 0)\n",
    "y_train = label_map(y_train, [2, 3], 1)\n",
    "y_test = label_map(y_test, [0, 1], 0)\n",
    "y_test = label_map(y_test, [2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306b3df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 2])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(x_train)\n",
    "print(x_train.shape)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db32a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size): # NN structure\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear_2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_tensor): # NN behavior\n",
    "        linear1 = self.linear_1(input_tensor)\n",
    "        relu = self.relu(linear1)\n",
    "        linear2 = self.linear_2(relu)\n",
    "        output = self.sigmoid(linear2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddda8c",
   "metadata": {},
   "source": [
    "회귀 / 분류 모델의 차이\n",
    "sigmoid -> binary_cross_entropy 사용\n",
    "softmax -> cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a68c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(2, 5)\n",
    "learning_rate = 0.03\n",
    "criterion = torch.nn.BCELoss() # Binary cross entropy\n",
    "epochs = 2000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate) # SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1122e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at 0 is 0.7154176831245422\n",
      "Train loss at 100 is 0.6449922323226929\n",
      "Train loss at 200 is 0.5660666823387146\n",
      "Train loss at 300 is 0.4664331078529358\n",
      "Train loss at 400 is 0.3495132327079773\n",
      "Train loss at 500 is 0.24527709186077118\n",
      "Train loss at 600 is 0.16971400380134583\n",
      "Train loss at 700 is 0.12110352516174316\n",
      "Train loss at 800 is 0.0908563956618309\n",
      "Train loss at 900 is 0.07129959762096405\n",
      "Train loss at 1000 is 0.05791493132710457\n",
      "Train loss at 1100 is 0.04839223250746727\n",
      "Train loss at 1200 is 0.0412762276828289\n",
      "Train loss at 1300 is 0.035811398178339005\n",
      "Train loss at 1400 is 0.03149789944291115\n",
      "Train loss at 1500 is 0.028021156787872314\n",
      "Train loss at 1600 is 0.025169452652335167\n",
      "Train loss at 1700 is 0.022795137017965317\n",
      "Train loss at 1800 is 0.020792633295059204\n",
      "Train loss at 1900 is 0.0190841406583786\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train() # train mode\n",
    "    optimizer.zero_grad() # reset the gradients of model parameters\n",
    "    train_output = model(x_train)\n",
    "    train_loss = criterion(train_output.squeeze(), y_train)\n",
    "    if epoch % 100 == 0:\n",
    "        print('Train loss at {} is {}'.format(epoch, train_loss.item()))\n",
    "    train_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05af2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Training, test loss is 0.030878927558660507\n"
     ]
    }
   ],
   "source": [
    "model.eval() # evaluation mode\n",
    "test_loss = criterion(torch.squeeze(model(x_test)), y_test)\n",
    "print('After Training, test loss is {}'.format(test_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f787b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict format of the model: OrderedDict({'linear_1.weight': tensor([[ 0.4631, -0.2895],\n",
      "        [-1.6329, -1.6336],\n",
      "        [ 1.3159, -1.3984],\n",
      "        [-1.3586,  1.3008],\n",
      "        [ 1.4161,  1.5173]]), 'linear_1.bias': tensor([-0.1403, -0.0144,  0.0104,  0.0200, -0.1874]), 'linear_2.weight': tensor([[ 0.4013, -2.2527,  1.6661,  1.8111, -1.9711]]), 'linear_2.bias': tensor([0.7467])})\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './model.pt')\n",
    "print('state_dict format of the model: {}'.format(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6b0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prob. that [-1,1] has label 1 is 0.99631267786026\n"
     ]
    }
   ],
   "source": [
    "new_model = NeuralNet(2, 5)\n",
    "new_model.load_state_dict(torch.load('./model.pt'))\n",
    "new_model.eval()\n",
    "print('The prob. that [-1,1] has label 1 is {}'.format(new_model(torch.FloatTensor([-1,1])).item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
